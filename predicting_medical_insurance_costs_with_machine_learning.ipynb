{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predicting_medical_insurance_costs_with_machine_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usX4FO1UIYiv"
      },
      "source": [
        "Anthony Isensee\n",
        "\n",
        "To give credit where credit is due, the stragies demonstrated by this project are derived from the book *Hands-On Machine Learning with Scikit-Learn, Keras, & TensorFlow*, a machine learning guide by Aurélien Géron. I highly recommend this textbook as an incredible resource for the individual wishing to utilize the incredible strength of machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRf8ndJfMoWH"
      },
      "source": [
        "# The Goal - Predicting Medical Insurance Costs\n",
        "\n",
        "Using the dataset from https://www.kaggle.com/mirichoi0218/insurance/home our goal is to use machine learning to predict the medical insurance costs incurred by unique individuals based on feature labels defining information gathered about the individuals.\n",
        "\n",
        "We utilize the following strategy to achieve this goal:\n",
        "\n",
        "1. Get the data.\n",
        "2. Explore the data.\n",
        "3. Prepare the data.\n",
        "4. Select, train, and evaluate a model using the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfLcbKaiS5Q4"
      },
      "source": [
        "# 0. Basic Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE95ZFhKS4tE"
      },
      "source": [
        "# Support Python2 and Python3 functions\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Numpy for number processing.\n",
        "import numpy as np\n",
        "\n",
        "# Set a 'random' seed for consistent results across platforms.\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh9edaqmQJHE"
      },
      "source": [
        "# 1. Get the Data\n",
        "\n",
        "Here, we download a copy of the data to our local environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGmmnFoBMe3O"
      },
      "source": [
        "## Load Insurance Dataset to File ##\n",
        "\n",
        "# Operating system utilities, especially for directory creation and file storage.\n",
        "import os\n",
        "\n",
        "# Import library for data retrieval from URL.\n",
        "from six.moves import urllib\n",
        "\n",
        "# URL for Data File\n",
        "# See https://www.kaggle.com/mirichoi0218/insurance/home for original source of dataset.\n",
        "DATSET_DOWNLOAD_URL = \"https://raw.githubusercontent.com/rlsummerscales/CPTR435/master/data/insurance.csv\"\n",
        "\n",
        "# Local path at which to store data.\n",
        "INSURANCE_DATASET_PATH = os.path.join(\"datasets\", \"insurance\")\n",
        "\n",
        "## Gather data from URL ##\n",
        "def fetch_insurance_data(insurance_url=DATSET_DOWNLOAD_URL, insurance_path=INSURANCE_DATASET_PATH):\n",
        "    \n",
        "    # Create a directory on the current OS to store the data in.\n",
        "    if not os.path.isdir(insurance_path):\n",
        "        os.makedirs(insurance_path)\n",
        "\n",
        "    # Build a local path for the data file\n",
        "    csv_path = os.path.join(insurance_path, \"insurance.csv\")\n",
        "\n",
        "    # Download the dataset\n",
        "    urllib.request.urlretrieve(insurance_url, csv_path)\n",
        "\n",
        "# Fetch the dataset and load into local directory\n",
        "fetch_insurance_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HZLjZgCOIO4"
      },
      "source": [
        "We then take that data and load it into a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CDGBp60LkqB"
      },
      "source": [
        "## Load Dataset .csv into Pandas Dataframe ##\n",
        "\n",
        "# Import pandas so we can actually use it's dataframe object\n",
        "import pandas as pd\n",
        "\n",
        "# Takes a file, loads it into a pandas dataframe, and returns that dataframe. \n",
        "def load_insurance_data(insurance_path=INSURANCE_DATASET_PATH):\n",
        "    csv_path = os.path.join(insurance_path, \"insurance.csv\")\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "# Load data into dataframe\n",
        "insurance = load_insurance_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfYwgOiKNXLL"
      },
      "source": [
        "# 2. Explore the data\n",
        "\n",
        "We now find out more about our data. We do the following to get a taste of the data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRB17Mk8PF2J"
      },
      "source": [
        "# Display the first few rows for sampling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "SiJRxLHDNt25",
        "outputId": "a96a3298-666e-43e8-ceff-7f6c061f16e8"
      },
      "source": [
        "# Display the first few rows for sampling.\n",
        "insurance.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRmc_uJPPKA5"
      },
      "source": [
        "# Display the value counts for sex, smoker, and region. \n",
        "\n",
        "Essentially, these are the values present in the dataset, as well as how many of that value are present in each set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha60S8YXOZTj",
        "outputId": "4be15f4b-246e-42a3-a00d-7bc9120c09a6"
      },
      "source": [
        "# Display value counts for sex\n",
        "insurance[\"sex\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "male      676\n",
              "female    662\n",
              "Name: sex, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFqhXR23O9CA",
        "outputId": "6e5803f3-a745-4bd1-acc8-2a99afd7a3b3"
      },
      "source": [
        "# Display value counts for smoker\n",
        "insurance[\"smoker\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no     1064\n",
              "yes     274\n",
              "Name: smoker, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUBp5NjxO-w5",
        "outputId": "80e98404-bac9-40c2-a901-e721760427b9"
      },
      "source": [
        "# Display value counts for region\n",
        "insurance[\"region\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "southeast    364\n",
              "southwest    325\n",
              "northwest    325\n",
              "northeast    324\n",
              "Name: region, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uya0G53DPi2l"
      },
      "source": [
        "# Histograms of Numerical Features\n",
        "\n",
        "We then plot histograms for easy visual depictions of each feature. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "Kz3EV8LdPq8h",
        "outputId": "67aacad7-971c-4bd0-bf2c-2fe48b05bfbc"
      },
      "source": [
        "# Show plots inline\n",
        "%matplotlib inline\n",
        "\n",
        "# Import matplotlib's pyplot features\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Uses matplotlib.pyplot.hist to plot histograms\n",
        "insurance.hist(bins=50, figsize=(20,12))\n",
        "\n",
        "# Shows plots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x864 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We0qp8utQWq3"
      },
      "source": [
        "# Histogram & Data Observations\n",
        "\n",
        "In viewing the histograms, we make several observations:\n",
        "\n",
        "\n",
        "1.   The majority of individuals have 0 children. The next majority have 1, then 2, etc.\n",
        "2.   Data is limited to 5 child households.\n",
        "3.   The vast majority of charges lie between \\$0 and \\$15,000 dollars. (Assuming charges are in dollars.)\n",
        "4.   There is a very even distribution of age, *except for individuals younger than 20*.\n",
        "5.   Several values of age appear to have no data points (29, 41, and 53). Additionally, the cutoff for age data seems to be 65. This could limit our predictive capability for anyone who is those specific ages or older than 65.\n",
        "5.   Most individuals have a BMI of around 30%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh9A6tYiTqMC"
      },
      "source": [
        "# Stratified Split\n",
        "\n",
        "Now, we perform a stratified split of the dataset, using the smoker attribute as the primary feature we wish to split evenly. \n",
        "\n",
        "Note that we are only splitting once (we are not performing K-fold cross validation) and that our test set size will be 20%, meaning our training set size will naturally be the remaining 80%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErXO0AGNR8L3",
        "outputId": "7576bdb1-33f4-4385-fa1b-40d68b652ff3"
      },
      "source": [
        "# Import scikitlearn's stratified shuffle split.\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# We set up the desired parameters for our split.\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=51)\n",
        "\n",
        "# Spilt object is a generator. Need for loop to make it generate a split.\n",
        "# split(x, label) -> splits array x between train and test making sure that\n",
        "# each label (e.g. each income category) is equally represented in both train and test sets.\n",
        "# The probability distribution of the labels should be roughly the same in both sets.\n",
        "\n",
        "# We use a for loop to equally distribute items in the training and test sets.\n",
        "for train_index, test_index in split.split(insurance, insurance[\"smoker\"]):\n",
        "    print('Training samples: {}, testing samples: {}'\n",
        "          .format(train_index.shape, test_index.shape))\n",
        "    \n",
        "    stratified_training_set = insurance.loc[train_index]\n",
        "    stratified_testing_set = insurance.loc[test_index]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: (1070,), testing samples: (268,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdlMzPhtU8t3"
      },
      "source": [
        "# Verification of Stratified Split\n",
        "\n",
        "Now, we verify that the stratified split actually performed the split with roughly the same percentage of smokers in the training set as the test set. We divide each category (as we saw before, the answers no/yes) by the number of total items in the set to see the decimal percentage of each feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im-vahcyU8AM",
        "outputId": "aa82191a-9610-4785-a8fb-d7d5913423aa"
      },
      "source": [
        "# Decimal percentage of each feature in training set\n",
        "stratified_training_set[\"smoker\"].value_counts() / len(stratified_training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no     0.795327\n",
              "yes    0.204673\n",
              "Name: smoker, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZKMephcVlHC",
        "outputId": "9fdc8003-b978-4bbe-ee6f-d9bf1fc0e93b"
      },
      "source": [
        "# Decimal percentage of each feature in test set\n",
        "stratified_testing_set[\"smoker\"].value_counts() / len(stratified_testing_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no     0.794776\n",
              "yes    0.205224\n",
              "Name: smoker, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Yb6JziV0fp"
      },
      "source": [
        "Awesome! It's a very even distribution between test and training sets, at least based on this one feature. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhV26qcVBUVx"
      },
      "source": [
        "# Comparison to Random Split\n",
        "\n",
        "Out of curiosity, let's see what a randomized split might give us based on this sole feature!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ4iwTazW5C_"
      },
      "source": [
        "# Import the simple, randomized train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a random split\n",
        "example_training_set, example_testing_set = train_test_split(insurance, test_size=0.2, random_state=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxRLUobhXc0D",
        "outputId": "89a23750-a38c-4c27-d609-cc4aada9a24e"
      },
      "source": [
        "# Decimal percentage of each feature in example training set\n",
        "example_training_set[\"smoker\"].value_counts() / len(example_training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no     0.790654\n",
              "yes    0.209346\n",
              "Name: smoker, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUlnPxBAXdae",
        "outputId": "519bcb25-3258-4f4e-d94d-7549e4541e2e"
      },
      "source": [
        "# Decimal percentage of each feature in example training set\n",
        "example_testing_set[\"smoker\"].value_counts() / len(example_testing_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no     0.813433\n",
              "yes    0.186567\n",
              "Name: smoker, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWkkz90tV7bS"
      },
      "source": [
        "Definitely not as good, demonstrating how nice it can be to be able to perform a stratified split to have even distribution over your training and testing sets of a feature with particular importance!\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXBAkJCVX8yA"
      },
      "source": [
        "# Identify Correlations w/ Correlation Matrix\n",
        "\n",
        "Now, we wish to identify important correlations. One of the ways we can easily do this is with a correlation matrix, which shows us which values correspond to which other values the most often."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "HG2UwpBLYife",
        "outputId": "81577ca1-d370-49c7-8b92-53a6a77e3d74"
      },
      "source": [
        "# Create a correlation matrix\n",
        "insurance_correlation_matrix = insurance.corr()\n",
        "\n",
        "# Print results\n",
        "insurance_correlation_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.109272</td>\n",
              "      <td>0.042469</td>\n",
              "      <td>0.299008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>0.109272</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.012759</td>\n",
              "      <td>0.198341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>children</th>\n",
              "      <td>0.042469</td>\n",
              "      <td>0.012759</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.067998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>charges</th>\n",
              "      <td>0.299008</td>\n",
              "      <td>0.198341</td>\n",
              "      <td>0.067998</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               age       bmi  children   charges\n",
              "age       1.000000  0.109272  0.042469  0.299008\n",
              "bmi       0.109272  1.000000  0.012759  0.198341\n",
              "children  0.042469  0.012759  1.000000  0.067998\n",
              "charges   0.299008  0.198341  0.067998  1.000000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVyhPV5CY8mW"
      },
      "source": [
        "# Correlation Observations\n",
        "\n",
        "Looking at this correlation matrix, we see the highest correlations (other than between features and themselves) occur between age and charges. We are very interested in the charges category, so we use further code to isolate and order by significance. This doesn't simplify too much since there are currently so few numerical categories, but it does help us to see which categories might have the largest influence on costs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNNJ0aikhia3",
        "outputId": "db9062b5-1253-4bbd-b2ad-b58bf872afe9"
      },
      "source": [
        "insurance_correlation_matrix[\"charges\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "charges     1.000000\n",
              "age         0.299008\n",
              "bmi         0.198341\n",
              "children    0.067998\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dFSrnBWh9eh"
      },
      "source": [
        "As we can see, it runs age, bmi, and then finally children (children having comparitively little correlation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ4VuCrQSPE3"
      },
      "source": [
        "# 3. Prepare the data\n",
        "\n",
        "Now, we want to actually start processing our data so that we can train a machine learning model with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHFZZ7W1Brv9"
      },
      "source": [
        "# Remove Desired Output Labels\n",
        "\n",
        "We begin by copying the output labels (the charges category) from the datasets. Then, we remove the labels from the main dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd3GAQIiSMai"
      },
      "source": [
        "# Copy out labels from sets\n",
        "stratified_training_set_labels = stratified_training_set[\"charges\"].copy()\n",
        "stratified_testing_set_labels = stratified_testing_set[\"charges\"].copy()\n",
        "\n",
        "# Drop output labels from both sets\n",
        "stratified_training_set = stratified_training_set.drop(\"charges\", axis=1)\n",
        "stratified_testing_set = stratified_testing_set.drop(\"charges\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHF5hy7uV0qm"
      },
      "source": [
        "# Check for Missing Attribute Values\n",
        "\n",
        "Now, we check for missing attribute values. As we can see, there are none, which makes our lives significantly easier. Yay for complete datasets!\n",
        "\n",
        "If there were incomplete rows, we could use scikitlearn's Imputer class to fix missing values in a data set using a specific strategy. (Or, if we're feeling lazy, we could drop the rows with missing features. If we're feeling *really* lazy we could even drop the feature.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Tgd2cBwHSMFo",
        "outputId": "018497f4-240a-422b-93c7-80fe51d758b3"
      },
      "source": [
        "incomplete_rows = insurance[insurance.isnull().any(axis=1)].head()\n",
        "incomplete_rows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [age, sex, bmi, children, smoker, region, charges]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mdp0vS0Zlwi"
      },
      "source": [
        "# One Hot Encode Categorical Features\n",
        "\n",
        "Unfortunately, looking at our data as a whole, see that only four of our features are numerical data. We'd like to be able to convert the rest of the features to numerical data so that we can easily feed the dataset to a Machine Learning algorithm. So, we make changes to the data.\n",
        "\n",
        "We note that we will need to process 3 features: sex, smoker, and region. Thankfully (and I found this out the hard way) we can do them all at once.\n",
        "\n",
        "While we could use label encoding to assign a certain number to each unique label, this could imply some sort of numeric scale to be associated with the labels. Since we do not desire this, we use a one-hot encoding approach. To do this, we create an array with the same number of spaces as we have number of labels for each feature. Then, we set solely the indexed position in the array associated with that label to 1, leaving all other values at 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN9TTo7NbPTM",
        "outputId": "17b98851-643e-4730-ac6a-758db0ff6c0a"
      },
      "source": [
        "# Import OneHotEncoder to perform one-hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Create the encoder\n",
        "category_encoder = OneHotEncoder()\n",
        "\n",
        "# Set the category\n",
        "insurance_category_to_encode = insurance[[\"sex\", \"smoker\", \"region\"]]\n",
        "\n",
        "# Perform the encoding\n",
        "insurance_only_categorical_features = category_encoder.fit_transform(insurance_category_to_encode)\n",
        "\n",
        "# Convert from default sparse array to normal array and print\n",
        "insurance_only_categorical_features.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 1., 1., ..., 0., 1., 0.],\n",
              "       [0., 1., 1., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [1., 0., 1., ..., 0., 1., 0.],\n",
              "       [1., 0., 1., ..., 0., 0., 1.],\n",
              "       [1., 0., 0., ..., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUDaxXK6jvUi"
      },
      "source": [
        "# Housekeeping\n",
        "\n",
        "Additionally, now that we've encoded the categorical features and stored just those in their own array, we want to remove them from the original dataset so that we can isolate only the numerical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvmmTvLckCoM"
      },
      "source": [
        "insurance_only_numerical_features = insurance.drop('sex', axis=1)\n",
        "insurance_only_numerical_features = insurance_only_numerical_features.drop('smoker', axis=1)\n",
        "insurance_only_numerical_features = insurance_only_numerical_features.drop('region', axis=1)\n",
        "insurance_only_numerical_features = insurance_only_numerical_features.drop('charges', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTSAQmJwYqWk"
      },
      "source": [
        "# Create a Full Pipeline\n",
        "\n",
        "Now, we must create a class to select numerical and categorical features from our dataset. This will be essential to the pipeline we are about to set up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxybvIpobbT1"
      },
      "source": [
        "# Import for DataFrameSelector class to function\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Create a class to select numerical or categorical columns \n",
        "# since Scikit-Learn doesn't handle DataFrames yet\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et2WEXrGimmy"
      },
      "source": [
        "First, we import the pipeline class so that we may utilize its functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GVyfGrFiZvT"
      },
      "source": [
        "# Import the pipeline class from scikitlearn\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCe3xnlOmOsa"
      },
      "source": [
        "Now, we create a pipeline for numerical and categorical functions, then join those two pipelines together to create one beautiful pipeline.\n",
        "\n",
        "Numerical features pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niL8ycJylhYx"
      },
      "source": [
        "## Numerical Features Pipeline ##\n",
        "\n",
        "# Define numerical attributes to select with our numerical pipeline.\n",
        "# These are the features labels only present in the ridiculously \n",
        "# long variable insurance_only_numerical_features. \n",
        "numerical_attributes = list(insurance_only_numerical_features)\n",
        "\n",
        "# Create a pipeline for preparing numerical features\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('selector', DataFrameSelector(numerical_attributes)),\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV-6FrWcmYri"
      },
      "source": [
        "Categorical features pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUGzBA2VlgHL"
      },
      "source": [
        "## Categorical Features Pipeline ##\n",
        "\n",
        "# Define categorical attributes to select with our categorical pipeline\n",
        "category_attributes = [\"sex\", \"smoker\", \"region\"]\n",
        "\n",
        "# Create a pipeline for preparing categorical features\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('selector', DataFrameSelector(category_attributes)),\n",
        "    ('category_encoder', OneHotEncoder(sparse=False))\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMbNzhdKmaqC"
      },
      "source": [
        "Combined pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnZnLTF3dbv6"
      },
      "source": [
        "## Combine Both Pipelines ##\n",
        "\n",
        "# Import scikitlearn's FeatureUnion to combine pipelines\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "full_pipeline = FeatureUnion(transformer_list=[\n",
        "    (\"numerical_pipeline\", numerical_pipeline),\n",
        "    (\"categorical_pipeline\", categorical_pipeline),\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G72ORaiOmgB0"
      },
      "source": [
        "And finally, we run a quick check on our data to make sure our pipeline is working. All we see is numbers, so we appear to be golden!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkWpHu-nmr0z",
        "outputId": "956859f4-67da-4c38-d21b-0b2dcab4ab2e"
      },
      "source": [
        "insurance_prepared = full_pipeline.fit_transform(insurance)\n",
        "insurance_prepared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19.  , 27.9 ,  0.  , ...,  0.  ,  0.  ,  1.  ],\n",
              "       [18.  , 33.77,  1.  , ...,  0.  ,  1.  ,  0.  ],\n",
              "       [28.  , 33.  ,  3.  , ...,  0.  ,  1.  ,  0.  ],\n",
              "       ...,\n",
              "       [18.  , 36.85,  0.  , ...,  0.  ,  1.  ,  0.  ],\n",
              "       [21.  , 25.8 ,  0.  , ...,  0.  ,  0.  ,  1.  ],\n",
              "       [61.  , 29.07,  0.  , ...,  1.  ,  0.  ,  0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siKSP0_4n2pR"
      },
      "source": [
        "# 4. Select, train, and evaluate a model\n",
        "\n",
        "Finally! The fun part. Now, we can use our data pipelinet to prepare any dataset, and feed the resulting dataset to any machine learning model.\n",
        "\n",
        "In this case, we will compare performance between three different machine learning algorithms:\n",
        "\n",
        "1. Linear Regression\n",
        "2. Decision Tree Regression\n",
        "3. Random Forest Regression.\n",
        "\n",
        "For all three models, we will eventually use 10-fold cross-validation to ensure the most accurate results. That said, we begin *without* Cross-Validation to make sure the models are working correctly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm3ORMlLWKZ6"
      },
      "source": [
        "# Prepare Data\n",
        "\n",
        "We start by using our pipeline to clean and process both our training and testing sets. We ammend \"ready\" to the end of the variable name to indicate the data's final status. We also re-label the variables caryrying our output labels so that they match the format of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU6LBvwmWNXb",
        "outputId": "a8bd3ca6-bc81-4cdc-9787-b6aa4834fe65"
      },
      "source": [
        "# Run insurance dataset through full pipeline.\n",
        "# We note that we are using the stratified training/testing sets, \n",
        "# or stratified_training_set and stratified_testing_set\n",
        "train_insurance_data_ready = full_pipeline.fit_transform(stratified_training_set)\n",
        "test_insurance_data_ready = full_pipeline.fit_transform(stratified_testing_set)\n",
        "\n",
        "# Re-label variables carrying output labels (the charges category)\n",
        "train_insurance_labels = stratified_training_set_labels\n",
        "test_insurance_labels = stratified_testing_set_labels\n",
        "\n",
        "# Print information about our data\n",
        "# Note that data is (number_of_instances, number_of_labels)\n",
        "print(\"Training set: {}\".format(train_insurance_data_ready.shape))\n",
        "print(\"Test set: {}\".format(test_insurance_data_ready.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (1070, 11)\n",
            "Test set: (268, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVd4FSNGaYUi"
      },
      "source": [
        "# Train Basic Models\n",
        "\n",
        "We begin by training a linear regression model with our training data. We'll soon use 10-fold cross-validation with identical models as well, but for now we want to establish a baseline metric with a single version of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6SqEUixae6D",
        "outputId": "be3fa546-05f0-4abf-bdf1-16c0865eeafa"
      },
      "source": [
        "# Import for Linear Regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create the model\n",
        "linear_regression_model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "linear_regression_model.fit(train_insurance_data_ready, train_insurance_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkNDFr-nmu11"
      },
      "source": [
        "Of course, just training the model doesn't do much for us. We'd now like to use that model to make predictions about other data, here our test set. We will use Root Mean Squared error as our metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmLX7mcUmkwu",
        "outputId": "2b708d67-b308-4028-9198-badb5988dcdf"
      },
      "source": [
        "# Import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Using our model, predict values for each sample in the testing set\n",
        "insurance_cost_predictions = linear_regression_model.predict(train_insurance_data_ready)\n",
        "\n",
        "# Create RMSE of linear regression model on training data\n",
        "linear_regression_mse = mean_squared_error(train_insurance_labels, insurance_cost_predictions)\n",
        "linear_regression_rmse = np.sqrt(linear_regression_mse)\n",
        "\n",
        "# Print results\n",
        "print(\"RMSE of Linear Regression Model: {}\".format(linear_regression_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of Linear Regression Model: 5880.664402701746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLHwzhnHoxJ_"
      },
      "source": [
        "Now, we train a basic Decision Tree Regression model with the same data and calculate its RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTaxK29aowdw",
        "outputId": "bc2faed9-4054-497d-b4fe-48d64e1386b0"
      },
      "source": [
        "# Import DecisionTreeRegressor from scikitlearn\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Create the model\n",
        "decision_tree_regression_model = DecisionTreeRegressor(random_state=21)\n",
        "\n",
        "# Train the model\n",
        "decision_tree_regression_model.fit(train_insurance_data_ready, train_insurance_labels)\n",
        "\n",
        "# Using our model, predict values for each sample in the testing set\n",
        "decision_tree_insurance_cost_predictions = decision_tree_regression_model.predict(train_insurance_data_ready)\n",
        "\n",
        "# Create RMSE of model on training data\n",
        "decision_tree_mse = mean_squared_error(train_insurance_labels, decision_tree_insurance_cost_predictions)\n",
        "decision_tree_rmse = np.sqrt(decision_tree_mse)\n",
        "\n",
        "# Print results\n",
        "print(\"RMSE of Decision Tree Regression Model: {}\".format(decision_tree_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of Decision Tree Regression Model: 270.2373612509658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKgWSEznqFvR"
      },
      "source": [
        "We see that the RMSE of decision Tree Regression is significantly lower. Decision trees are much better at memorizing the training set, however, so we won't really know just how good this specific model is until we ask it to predict our test set.\n",
        "\n",
        "That said, another way we can test it is to implement many decision trees with a Random Forest Regressor, which uses a number of slightly different trees to come up with the final result. So, we train a basic Random Forest Regressor model to do just that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGn_cah-qhMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882fa57e-1441-4508-9d69-210903cab7c0"
      },
      "source": [
        "# Import RandomForestRegressor model from scikitlearn\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Create the model. Note that we are creating 10 separate decision trees.\n",
        "random_forest_regression_model = RandomForestRegressor(random_state=21, n_estimators=10)\n",
        "\n",
        "# Train the model\n",
        "random_forest_regression_model.fit(train_insurance_data_ready, train_insurance_labels)\n",
        "\n",
        "# Using our model, predict values for each sample in the testing set\n",
        "random_forest_insurance_cost_predictions = random_forest_regression_model.predict(train_insurance_data_ready)\n",
        "\n",
        "# Create RMSE of model on training data\n",
        "random_forest_regression_mse = mean_squared_error(train_insurance_labels, random_forest_insurance_cost_predictions)\n",
        "random_forest_regression_rmse = np.sqrt(random_forest_regression_mse)\n",
        "\n",
        "# Print results\n",
        "print(\"RMSE of Random Forst Regression Model: {}\".format(random_forest_regression_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of Random Forst Regression Model: 2059.2719778674386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqUm_jrrsfRI"
      },
      "source": [
        "Awesome! It looks like creating a 'committee' of trees causes our model to perform significantly less overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtphq0dB_ood"
      },
      "source": [
        "# K-Fold Cross-Validation\n",
        "\n",
        "Finally, now that we've established each individual model, we run each with 10-fold cross-validation, just to see how well each model holds up when trained with slightly different data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKJGp24u2G5j",
        "outputId": "f3fd01a2-c30b-49f5-ccbc-5530474b51ed"
      },
      "source": [
        "## Linear Regression ##\n",
        "\n",
        "# Import for cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Run 10-fold cross-validation with linear regression model.\n",
        "linear_regression_10f_cv_scores = cross_val_score(\n",
        "    linear_regression_model, train_insurance_data_ready, \n",
        "    stratified_training_set_labels, scoring=\"neg_mean_squared_error\", \n",
        "    cv=10)\n",
        "\n",
        "# Calculate RMSE of scores\n",
        "linear_regression_rmse_scores = np.sqrt(-linear_regression_10f_cv_scores)\n",
        "\n",
        "# Print a list of RMSE values\n",
        "print(\"Results of 10-f c-v for Linear Regression:\")\n",
        "print(linear_regression_rmse_scores)\n",
        "\n",
        "# Load scores into panda DataFrame to quickly calculate stats\n",
        "print(\"Measurements on results:\")\n",
        "print(pd.Series(linear_regression_rmse_scores).describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of 10-f c-v for Linear Regression:\n",
            "[5367.44838036 6624.94109849 6536.01561369 6134.72010058 5911.99635761\n",
            " 5546.25088899 5551.72707151 6711.70655398 5653.46146106 5170.37965706]\n",
            "Measurements on results:\n",
            "count      10.000000\n",
            "mean     5920.864718\n",
            "std       554.073586\n",
            "min      5170.379657\n",
            "25%      5547.619935\n",
            "50%      5782.728909\n",
            "75%      6435.691735\n",
            "max      6711.706554\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4uedD7XEnB3"
      },
      "source": [
        "Interestingly, we note that the average RMSE is actually less accurate than the basic linear regression model that did not have 10-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "382QxjCwsn6M",
        "outputId": "de671f9c-660f-456b-9819-670e062407d8"
      },
      "source": [
        "## Decision Tree Regression ##\n",
        "\n",
        "# Run 10-fold cross-validation with a decision tree regression model.\n",
        "decision_tree_regression_10f_cv_scores = cross_val_score(\n",
        "    decision_tree_regression_model, train_insurance_data_ready, \n",
        "    stratified_training_set_labels, scoring=\"neg_mean_squared_error\", \n",
        "    cv=10)\n",
        "\n",
        "# Calculate RMSE of scores\n",
        "decision_tree_regression_rmse_scores = np.sqrt(-decision_tree_regression_10f_cv_scores)\n",
        "\n",
        "# Print a list of RMSE values\n",
        "print(\"Results of 10-f c-v for Decision Tree Regression:\")\n",
        "print(decision_tree_regression_rmse_scores)\n",
        "\n",
        "# Load scores into panda DataFrame to quickly calculate stats\n",
        "print(\"Measurements on results:\")\n",
        "print(pd.Series(decision_tree_regression_rmse_scores).describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of 10-f c-v for Decision Tree Regression:\n",
            "[5754.25205919 7401.14211875 6124.49508936 6461.32232339 5145.01809391\n",
            " 5255.91531961 5041.53994256 6907.686776   7239.23119248 5215.26701215]\n",
            "Measurements on results:\n",
            "count      10.000000\n",
            "mean     6054.586993\n",
            "std       906.814207\n",
            "min      5041.539943\n",
            "25%      5225.429089\n",
            "50%      5939.373574\n",
            "75%      6796.095663\n",
            "max      7401.142119\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VB4qbphFCo_"
      },
      "source": [
        "Again, we note the mean of the decion tree's 10-fold cross-validation. It's significantly higher than the basic decision tree (without 10-f c-v), but, since we suspected that the pinpoint accuracy was due to overfitting, it's good to see this back to roughly the same level as linear regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoukzA3K2LfH",
        "outputId": "a977b84d-2ad4-4f64-fd77-632666140551"
      },
      "source": [
        "## Random Forest Regression ##\n",
        "\n",
        "# Run 10-fold cross-validation with a random forst regression model.\n",
        "random_forest_regression_10f_cv_scores = cross_val_score(\n",
        "    random_forest_regression_model, train_insurance_data_ready, \n",
        "    stratified_training_set_labels, scoring=\"neg_mean_squared_error\", \n",
        "    cv=10)\n",
        "\n",
        "# Calculate RMSE of scores\n",
        "random_forest_regression_rmse_scores = np.sqrt(-random_forest_regression_10f_cv_scores)\n",
        "\n",
        "# Print a list of RMSE values\n",
        "print(\"Results of 10-f c-v for Random Forst Regression:\")\n",
        "print(random_forest_regression_rmse_scores)\n",
        "\n",
        "# Load scores into panda DataFrame to quickly calculate stats\n",
        "print(\"Measurements on results:\")\n",
        "print(pd.Series(random_forest_regression_rmse_scores).describe())\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of 10-f c-v for Random Forst Regression:\n",
            "[4887.78733286 5296.04570272 5826.67486433 4824.12073706 4597.84840622\n",
            " 3651.99530137 4110.32254631 5254.54703586 4438.08770874 4160.94194546]\n",
            "Measurements on results:\n",
            "count      10.000000\n",
            "mean     4704.837158\n",
            "std       649.638800\n",
            "min      3651.995301\n",
            "25%      4230.228386\n",
            "50%      4710.984572\n",
            "75%      5162.857110\n",
            "max      5826.674864\n",
            "dtype: float64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvXnkCKaFzw5"
      },
      "source": [
        "Finally, we observe that the average RMSE of a Random Forest with 10-fold cross-validation is *significantly* more accurate than either of the other two algorithms. We've used all of the tools in our toolbox to get a more accurate result, and it has paid off! If we're bold, we might even make a prediction that when applied to our testing set, the Random Forest model may best predict the desired output labels. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y22QaNVGxhOG"
      },
      "source": [
        " # Predict Tesing Set Labels & Evaluate RMSE of Each Model\n",
        " \n",
        "To check this prediction, we run our three models against our testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVxKvOiJyZ5A",
        "outputId": "699b749b-5b89-4541-a6e1-82dbd7b3abc9"
      },
      "source": [
        "# Using our Linear Regression model, predict values for the test set\n",
        "insurance_cost_predictions_test = linear_regression_model.predict(test_insurance_data_ready)\n",
        "\n",
        "# Create RMSE of linear regression model on training data\n",
        "linear_regression_mse = mean_squared_error(test_insurance_labels, insurance_cost_predictions_test)\n",
        "linear_regression_rmse = np.sqrt(linear_regression_mse)\n",
        "\n",
        "# Print results\n",
        "print(\"RMSE of Linear Regression Model on Testing Set: {}\".format(linear_regression_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of Linear Regression Model on Testing Set: 6688.995219851242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ155MqczAM8",
        "outputId": "e7a0ae69-2031-421d-86ec-ca41bb538b70"
      },
      "source": [
        "# Using our Decision Tree model, predict values for the test set\n",
        "decision_tree_insurance_cost_predictions_test = decision_tree_regression_model.predict(test_insurance_data_ready)\n",
        "\n",
        "# Create RMSE of model on training data\n",
        "decision_tree_mse = mean_squared_error(test_insurance_labels, decision_tree_insurance_cost_predictions_test)\n",
        "decision_tree_rmse = np.sqrt(decision_tree_mse)\n",
        "\n",
        "# Print results\n",
        "print(\"RMSE of Decision Tree Regression Model on Testing Set: {}\".format(decision_tree_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of Decision Tree Regression Model on Testing Set: 6918.7859652121715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GuJdE-Hzgoa",
        "outputId": "9486e7b8-d94f-4eb1-dded-d416edb57dec"
      },
      "source": [
        "# Using our Random Forest model, predict values for the test set\n",
        "random_forest_insurance_cost_predictions_test = random_forest_regression_model.predict(test_insurance_data_ready)\n",
        "\n",
        "# Create RMSE of model on training data\n",
        "random_forest_regression_mse = mean_squared_error(test_insurance_labels, \n",
        "                                                  random_forest_insurance_cost_predictions_test)\n",
        "random_forest_regression_rmse = np.sqrt(random_forest_regression_mse)\n",
        "\n",
        "# Print results\n",
        "print(\"RMSE of Random Forest Regression Model on Testing Set: {}\".format(random_forest_regression_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of Random Forest Regression Model on Testing Set: 5554.899481383516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MHBtwsq0SCx"
      },
      "source": [
        "# Final Remarks on the Results\n",
        "\n",
        "After predicting the results of our testing data with all of our trained models we see that while performance is similar to within roughly $1000 between all models, the Random Forest Regression model has a clear lead in accuracy when making predictions about our testing set.\n",
        "\n",
        "It is especially interesting to note that a single decision tree has a higher RMSE than a simpler linear regression model (by about \\$250). However, as soon as we combine multiple, slightly different decision trees into one model, that model beats out basic linear regression by a substantial amount (roughly \\$1000). Fantastically, we were able to predict this when comparing the RMSE of a single decision tree to the average of multiple decision trees (via 10-fold cross-validation).\n",
        "\n",
        "Moving forward, if we were to utilize one of these models in a production environment, we would a) want more data (and potentially labels) to do more training, thus producing better predictions and b) we would primarily use the random forest regression model as opposed to the other two models."
      ]
    }
  ]
}